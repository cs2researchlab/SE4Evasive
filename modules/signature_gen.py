"""
SymbolicHunter Signature Generation Module
Auto-generates YARA, Snort, and SIGMA signatures for detection
"""

import hashlib
import os
from datetime import datetime
from collections import Counter

class SignatureGenerator:
    def __init__(self, binary_path, analysis_results):
        """
        Initialize signature generator
        
        Args:
            binary_path: Path to analyzed binary
            analysis_results: Dictionary with analysis results
        """
        self.binary_path = binary_path
        self.results = analysis_results
        self.binary_data = self._read_binary()
        self.binary_name = os.path.basename(binary_path)
    
    def _read_binary(self):
        """Read binary file"""
        try:
            with open(self.binary_path, 'rb') as f:
                return f.read()
        except:
            return b''
    
    def generate_yara_rule(self):
        """Generate YARA rule for malware detection"""
        # Calculate hashes
        md5 = hashlib.md5(self.binary_data).hexdigest()
        sha256 = hashlib.sha256(self.binary_data).hexdigest()
        
        # Extract dangerous API calls
        dangerous_apis = self.results.get('dangerous_functions', [])
        api_imports = [api['name'] for api in dangerous_apis[:10]]
        
        # Get taint sinks
        taint_sinks = self.results.get('taint_analysis', {}).get('tainted_sinks', [])
        
        # Build strings section
        strings_section = ""
        if api_imports:
            strings_section = "    strings:\n"
            for i, api in enumerate(api_imports, 1):
                strings_section += f'        $api{i} = "{api}" ascii wide\n'
        
        # Add exploit patterns
        if taint_sinks:
            strings_section += '        $pattern1 = { 90 90 90 90 90 }  // NOP sled\n'
            strings_section += '        $pattern2 = { 31 C0 }  // XOR EAX, EAX\n'
        
        # Build condition
        condition = "    condition:\n"
        if api_imports:
            condition += f"        {len(api_imports)} of ($api*)"
            if taint_sinks:
                condition += " and any of ($pattern*)"
        else:
            condition += "        filesize < 10MB"
        
        yara_rule = f"""
rule SymbolicHunter_{self.binary_name.replace('.', '_')}_{datetime.now().strftime('%Y%m%d')}
{{
    meta:
        description = "Auto-generated by SymbolicHunter"
        author = "SymbolicHunter"
        date = "{datetime.now().strftime('%Y-%m-%d')}"
        hash_md5 = "{md5}"
        hash_sha256 = "{sha256}"
        risk_level = "{self._assess_risk()}"
        vulnerabilities = "{sum(len(v) for v in self.results.get('vulnerabilities', {}).values())}"
        taint_sinks = "{len(taint_sinks)}"
        
{strings_section}
{condition}
}}
"""
        return yara_rule
    
    def generate_snort_rule(self):
        """Generate Snort/Suricata rule for network detection"""
        # Extract network-related findings
        dangerous_apis = self.results.get('dangerous_functions', [])
        network_apis = [api for api in dangerous_apis if api.get('category') == 'network']
        
        if not network_apis:
            return "# No network activity detected - Snort rule not applicable"
        
        # Get exploit inputs that might be sent over network
        taint_sinks = self.results.get('taint_analysis', {}).get('tainted_sinks', [])
        
        # Build content patterns
        patterns = []
        for sink in taint_sinks[:3]:
            if 'exploit_hex' in sink:
                hex_data = sink['exploit_hex'][:40]  # First 40 chars
                patterns.append(hex_data)
        
        snort_rule = f"""
# Auto-generated Snort rule by SymbolicHunter
# Date: {datetime.now().strftime('%Y-%m-%d')}
# Binary: {self.binary_name}

alert tcp any any -> any any (
    msg:"SymbolicHunter - Potential {self.binary_name} exploit detected";
    flow:established,to_server;
"""
        
        if patterns:
            snort_rule += f'    content:"|{patterns[0][:20]}|";\n'
        
        snort_rule += f"""    reference:url,github.com/yourusername/SymbolicHunter;
    classtype:attempted-admin;
    sid:9000001;
    rev:1;
)
"""
        return snort_rule
    
    def generate_sigma_rule(self):
        """Generate SIGMA rule for SIEM detection"""
        dangerous_apis = self.results.get('dangerous_functions', [])
        process_apis = [api for api in dangerous_apis if api.get('category') == 'process']
        
        sigma_rule = f"""
title: Suspicious Activity - {self.binary_name}
id: {hashlib.md5(self.binary_name.encode()).hexdigest()}
status: experimental
description: Auto-generated by SymbolicHunter - Detects suspicious process activity
author: SymbolicHunter
date: {datetime.now().strftime('%Y/%m/%d')}
references:
    - https://github.com/yourusername/SymbolicHunter
tags:
    - attack.execution
    - attack.defense_evasion
logsource:
    category: process_creation
    product: windows
detection:
    selection:
        Image|endswith:
            - '{self.binary_name}'
"""
        
        if process_apis:
            sigma_rule += "        CommandLine|contains:\n"
            for api in process_apis[:5]:
                sigma_rule += f"            - '{api['name']}'\n"
        
        sigma_rule += """    condition: selection
falsepositives:
    - Legitimate administrative activity
level: high
"""
        return sigma_rule
    
    def generate_ioc_list(self):
        """Generate Indicators of Compromise (IOCs)"""
        md5 = hashlib.md5(self.binary_data).hexdigest()
        sha1 = hashlib.sha1(self.binary_data).hexdigest()
        sha256 = hashlib.sha256(self.binary_data).hexdigest()
        
        iocs = f"""
# Indicators of Compromise (IOCs)
# Generated by SymbolicHunter
# Date: {datetime.now().strftime('%Y-%m-%d')}
# Binary: {self.binary_name}

## File Hashes
MD5: {md5}
SHA1: {sha1}
SHA256: {sha256}

## File Attributes
Name: {self.binary_name}
Size: {len(self.binary_data)} bytes
Architecture: {self.results.get('statistics', {}).get('architecture', 'Unknown')}

## Behavioral Indicators
"""
        
        # Add dangerous API calls
        dangerous_apis = self.results.get('dangerous_functions', [])
        if dangerous_apis:
            iocs += "\n### Suspicious API Calls:\n"
            # Use 'category' or 'type' field depending on what's available
            api_counts = Counter([
                api.get('category', api.get('type', 'unknown')) 
                for api in dangerous_apis
            ])
            for api, count in api_counts.most_common(10):
                iocs += f"- {api}: {count} occurrence(s)\n"
        
        # Add taint sinks
        taint_sinks = self.results.get('taint_analysis', {}).get('tainted_sinks', [])
        if taint_sinks:
            iocs += "\n### Vulnerability Indicators:\n"
            for sink in taint_sinks[:5]:
                vuln_type = sink.get('vulnerability_type', sink.get('type', 'Unknown'))
                iocs += f"- {vuln_type}: {sink['function']} at {sink['address']}\n"
        
        # Add anti-analysis techniques
        anti_analysis = self.results.get('anti_analysis', [])
        if anti_analysis:
            iocs += "\n### Anti-Analysis Techniques:\n"
            for tech in anti_analysis:
                iocs += f"- {tech['technique']}: {tech['function']}\n"
        
        return iocs
    
    def generate_all_signatures(self, output_dir):
        """Generate all signatures and save to directory"""
        os.makedirs(output_dir, exist_ok=True)
        
        files = {}
        
        # YARA rule
        yara_path = os.path.join(output_dir, f'{self.binary_name}.yar')
        with open(yara_path, 'w') as f:
            f.write(self.generate_yara_rule())
        files['yara'] = yara_path
        
        # Snort rule
        snort_path = os.path.join(output_dir, f'{self.binary_name}.rules')
        with open(snort_path, 'w') as f:
            f.write(self.generate_snort_rule())
        files['snort'] = snort_path
        
        # SIGMA rule
        sigma_path = os.path.join(output_dir, f'{self.binary_name}.yml')
        with open(sigma_path, 'w') as f:
            f.write(self.generate_sigma_rule())
        files['sigma'] = sigma_path
        
        # IOC list
        ioc_path = os.path.join(output_dir, f'{self.binary_name}_iocs.txt')
        with open(ioc_path, 'w') as f:
            f.write(self.generate_ioc_list())
        files['iocs'] = ioc_path
        
        return files
    
    def _assess_risk(self):
        """Assess risk level"""
        taint_sinks = len(self.results.get('taint_analysis', {}).get('tainted_sinks', []))
        anti_analysis = len(self.results.get('anti_analysis', []))
        total_vulns = sum(len(v) for v in self.results.get('vulnerabilities', {}).values())
        
        if taint_sinks > 0 or anti_analysis > 0:
            return "CRITICAL"
        elif total_vulns > 100:
            return "HIGH"
        elif total_vulns > 10:
            return "MEDIUM"
        else:
            return "LOW"


def generate_signatures(binary_path, analysis_results, output_dir='signatures'):
    """
    Convenience function to generate all signatures
    
    Args:
        binary_path: Path to binary
        analysis_results: Analysis results dictionary
        output_dir: Directory to save signatures
    
    Returns:
        Dictionary of generated file paths
    """
    generator = SignatureGenerator(binary_path, analysis_results)
    return generator.generate_all_signatures(output_dir)
